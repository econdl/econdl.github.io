<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>EconDL | Convolutional Neural Networks</title>
    <meta name="description" content="Lecture 2: Covers Convolutional Neural Networks
">

    <meta property="og:title" content="Convolutional Neural Networks">
    <meta property="og:type" content="website">
    <meta property="og:url" content="/intro/2023/01/19/lecture2.html">
    <meta property="og:description" content="Lecture 2: Covers Convolutional Neural Networks
">
    <meta property="og:site_name" content="">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:url" content="/intro/2023/01/19/lecture2.html">
    <meta name="twitter:title" content="Convolutional Neural Networks">
    <meta name="twitter:description" content="Lecture 2: Covers Convolutional Neural Networks
">

    <!-- TODO: Adding page thumbnail for social meida -->

    <!-- Canonical URL -->
    <link rel="canonical" href="/intro/2023/01/19/lecture2.html">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/assets/css/bulma.css">
    <link rel="stylesheet" href="/assets/css/syntax/manni.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          displayMath: [ ['$$','$$'] ],
          processEscapes: true,
        }
      });
    </script>
    
    <script type="text/javascript"
            src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    
    <!-- Add link to h2 ... h6 -->
    <!-- Ref: https://ben.balter.com/2014/03/13/pages-anchor-links/ -->
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script>
      $(function() {
        return $("h2, h3, h4, h5, h6").each(function(i, el) {
          var $el, icon, id;
          $el = $(el);
          id = $el.attr('id');
          icon = '<i class="fas fa-link"></i>';
          if (id) {
            return $el.append($("<a />").addClass("header-link").attr("href", "#" + id).html(icon));
          }
        });
      });
    </script>
    
    <script src="/assets/js/bulma-collapsible.min.js"></script>

    <!-- Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '');
</script>


</head>

<body>

    <div class="section">            
        <div class="container">
            
                <nav class="navbar" role="navigation">
    <div class="navbar-brand">
        <a class="navbar-item site-title" href="/">
            <strong>EconDL</strong>
        </a>

        <div class="navbar-burger" data-target="navbar-main"
            onclick="document.querySelector('.navbar-menu').classList.toggle('is-active');">
            <span></span>
            <span></span>
            <span></span>
        </div>
    </div>

    <div class="navbar-menu" id="navbar-main">
        <div class="navbar-end">
            <!-- navbar items -->
            
                
                    <a href="/" class="navbar-item"></a>
                
            
                
                    <a href="/packages.html" class="navbar-item">Packages</a>
                
            
                
                    <a href="/datasets.html" class="navbar-item">Datasets</a>
                
            
            <div class="navbar-item">
                
            </div>
        </div>
    </div>
</nav>
<div class="is-divider" style="margin-top: 0.5rem; margin-bottom: 3rem;"></div>
  
            
            <article class="content" style="margin-top: 3rem">
  <div class="columns">
    <div class="column is-2 is-hidden-mobile">
    </div>
    <div class="column is-8">
        <header class="article-header">
            <h1>Convolutional Neural Networks</h1>
            <div class="article-list-footer">
    <span class="article-list-date">
        January 19, 2023
    </span>
    <span class="article-list-divider">-</span>
    <span class="article-list-minutes">
        
        
        3 minute read
        
    </span>
    </span>
    
    <span class="article-list-divider">-</span>
    <span class="article-list-cat">Category:</span>
    
    <span class="field">
        
        <a href="/category/intro" class="article-list-item">
            Intro
        </a>
        
        
    </span>
    
    <span class="article-list-divider">-</span>
    <span class="article-list-cat">Tags:</span>
    
    <span class="field">
        
        <a href="/tag/deep learning" class="article-list-item">
            Deep learning
        </a>
        
        
    </span>
</div>
        </header>
        <h2 id="topics">Topics</h2>

<p>This post covers the second lecture in the course: “Convolutional Neural Networks.”</p>

<p>Convolutional Neural Networks (CNNs) revolutionized computer vision and played a central
role in ushering in the deep learning revolution. In this lecture, we will discuss the evolution of
CNNs, which form the backbone for many vision applications.</p>

<p>If you need an initial review of CNN architecture and concepts, consider reviewing the blog post listed first under “Web Resources” before watching the lecture or reviewing the accompanying notes.</p>

<h2 id="lecture-video">Lecture Video</h2>

<p><a href="https://www.youtube.com/watch?v=gDieFvhiF10&amp;ab_channel=MelissaDell" target="_blank">
 <img src="http://img.youtube.com/vi/gDieFvhiF10/mqdefault.jpg" alt="Watch the video" width="560" height="315" />
</a></p>

<p><a href="https://www.dropbox.com/s/0du6wqccw5gv73h/lecture_convnets_small.pdf?dl=0">Lecture notes</a></p>

<h2 id="references-cited-in-lecture-2-convolutional-neural-networks">References Cited in Lecture 2: Convolutional Neural Networks</h2>

<h4 id="academic-papers">Academic Papers</h4>

<ul>
  <li>
    <p>LeCun, Yan, Léon Bottou, Yoshua Bengio, and Patrick Haffner. <a href="http://www.hdcin.cn/2022/03/31/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/LeNet.pdf">“Gradient-based learning
applied to document recognition.”</a> Proceedings of the IEEE 86, no. 11 (1998): 2278-2324.</p>
  </li>
  <li>
    <p>Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. <a href="https://dl.acm.org/doi/pdf/10.1145/3065386">“Imagenet classification with deep
convolutional neural networks.”</a> Advances in neural information processing systems 25 (2012):
1097-1105 (AlexNet).</p>
  </li>
  <li>
    <p>Deng, Jia, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. <a href="https://hollis.harvard.edu/permalink/f/1mdq5o5/TN_cdi_ieee_primary_5206848">“Imagenet: A large-scale
hierarchical image database.”</a> In 2009 IEEE Conference on Computer Vision and Pattern
Recognition, pp. 248-255, 2009. (Notes: this is the dataset that has been used to develop and test
many advancements in computer vision, and is also one of the most cited papers in deep
learning. Benchmark datasets like this play a very central role in computer science research)</p>
  </li>
  <li>
    <p>Simonyan, Karen, and Andrew Zisserman. <a href="https://arxiv.org/pdf/1409.1556.pdf%E3%80%82">“Very deep convolutional networks for large-scale
image recognition</a> arXiv preprint arXiv:1409.1556 (2014) (VGGNet).
Szegedy, Christian, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov,
Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. “Going deeper with
convolutions.” In Proceedings of the IEEE conference on computer vision and pattern
recognition, pp. 1-9. 2015 (GoogLeNet).</p>
  </li>
  <li>
    <p>He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">“Deep Residual Learning for Image
Recognition.”</a> In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 770-778. 2016 (ResNet).</p>
  </li>
  <li>
    <p>Xie, Saining, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.pdf">“Aggregated residual
transformations for deep neural networks.”</a> In Proceedings of the IEEE conference on computer
vision and pattern recognition, pp. 1492-1500. 2017 (ResNeXt).</p>
  </li>
  <li>
    <p>Liu, Z., Mao, H., Wu, C. Y., Feichtenhofer, C., Darrell, T., &amp; Xie, S. (2022). <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.pdf">A convnet for the
2020s.</a> In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (pp. 11976-11986). (ConvNeXt; this may also be clearer after the Vision
Transformers lecture)</p>
  </li>
  <li>
    <p>Howard, M. Sandler, G. Chu, L.-C. Chen, B. Chen, M. Tan, W. Wang, Y. Zhu, R. Pang,
V. Vasudevan,, <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Howard_Searching_for_MobileNetV3_ICCV_2019_paper.pdf">Searching for mobilenetv3</a>, Proceedings of the IEEE/CVF international
conference on computer vision pp. 1314–1324 (2019).</p>
  </li>
</ul>

<h4 id="other-resources">Other Resources</h4>

<ul>
  <li>
    <p><a href="https://towardsdatascience.com/an-introduction-to-convolutional-neural-networks-eb0b60b58fd7">Blog post by C. Thomas</a></p>
  </li>
  <li>
    <p><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">Slightly more in-depth blog post by S. Saha</a>, also very helpful for basic concepts.</p>
  </li>
</ul>

<h4 id="code-bases">Code Bases</h4>

<ul>
  <li>
    <p>PyTorch ImageNet examples: <a href="https://github.com/pytorch/examples/tree/main/imagenet">https://github.com/pytorch/examples/tree/main/imagenet</a>. Implements a variety of convolutional architectures.</p>
  </li>
  <li>
    <p><a href="https://github.com/KaimingHe/deep-residual-networks">Official ResNet implementation</a></p>
  </li>
  <li>
    <p><a href="https://github.com/facebookresearch/ResNeXt">Official ResNeXt implementation from FAIR</a></p>
  </li>
  <li>
    <p><a href="https://github.com/facebookresearch/ConvNeXt">Official ConvNeXt implementation from FAIR</a></p>
  </li>
  <li>
    <p><a href="https://github.com/rwightman/pytorch-image-models">timm</a>: API and implementations for a wide variety of vision models, including ConvNeXt, ResNet, and Mobilenet</p>
  </li>
</ul>

<p><em>Image Source</em>: https://www.mathworks.com/help/deeplearning/ug/layers-of-a-convolutional-neural-network.html</p>

    </div>
  </div>
</article>

        </div>
    </div>
    

</body>

</html>