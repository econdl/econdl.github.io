<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>EconDL | Text Retrieval</title>
    <meta name="description" content="Lecture 12: Text Retrieval
">

    <meta property="og:title" content="Text Retrieval">
    <meta property="og:type" content="website">
    <meta property="og:url" content="/intro/2023/03/20/lecture12.html">
    <meta property="og:description" content="Lecture 12: Text Retrieval
">
    <meta property="og:site_name" content="">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:url" content="/intro/2023/03/20/lecture12.html">
    <meta name="twitter:title" content="Text Retrieval">
    <meta name="twitter:description" content="Lecture 12: Text Retrieval
">

    <!-- TODO: Adding page thumbnail for social meida -->

    <!-- Canonical URL -->
    <link rel="canonical" href="/intro/2023/03/20/lecture12.html">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/assets/css/bulma.css">
    <link rel="stylesheet" href="/assets/css/syntax/manni.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          displayMath: [ ['$$','$$'] ],
          processEscapes: true,
        }
      });
    </script>
    
    <script type="text/javascript"
            src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    
    <!-- Add link to h2 ... h6 -->
    <!-- Ref: https://ben.balter.com/2014/03/13/pages-anchor-links/ -->
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script>
      $(function() {
        return $("h2, h3, h4, h5, h6").each(function(i, el) {
          var $el, icon, id;
          $el = $(el);
          id = $el.attr('id');
          icon = '<i class="fas fa-link"></i>';
          if (id) {
            return $el.append($("<a />").addClass("header-link").attr("href", "#" + id).html(icon));
          }
        });
      });
    </script>
    
    <script src="/assets/js/bulma-collapsible.min.js"></script>

    <!-- Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '');
</script>


</head>

<body>

    <div class="section">            
        <div class="container">
            
                <nav class="navbar" role="navigation">
    <div class="navbar-brand">
        <a class="navbar-item site-title" href="/">
            <strong>EconDL</strong>
        </a>

        <div class="navbar-burger" data-target="navbar-main"
            onclick="document.querySelector('.navbar-menu').classList.toggle('is-active');">
            <span></span>
            <span></span>
            <span></span>
        </div>
    </div>

    <div class="navbar-menu" id="navbar-main">
        <div class="navbar-end">
            <!-- navbar items -->
            
                
                    <a href="/" class="navbar-item"></a>
                
            
                
                    <a href="/packages.html" class="navbar-item">Packages</a>
                
            
                
                    <a href="/datasets.html" class="navbar-item">Datasets</a>
                
            
            <div class="navbar-item">
                
            </div>
        </div>
    </div>
</nav>
<div class="is-divider" style="margin-top: 0.5rem; margin-bottom: 3rem;"></div>
  
            
            <article class="content" style="margin-top: 3rem">
  <div class="columns">
    <div class="column is-2 is-hidden-mobile">
    </div>
    <div class="column is-8">
        <header class="article-header">
            <h1>Text Retrieval</h1>
            <div class="article-list-footer">
    <span class="article-list-date">
        March 20, 2023
    </span>
    <span class="article-list-divider">-</span>
    <span class="article-list-minutes">
        
        
        2 minute read
        
    </span>
    </span>
    
    <span class="article-list-divider">-</span>
    <span class="article-list-cat">Category:</span>
    
    <span class="field">
        
        <a href="/category/intro" class="article-list-item">
            Intro
        </a>
        
        
    </span>
    
    <span class="article-list-divider">-</span>
    <span class="article-list-cat">Tags:</span>
    
    <span class="field">
        
        <a href="/tag/deep learning" class="article-list-item">
            Deep learning
        </a>
        
        
    </span>
</div>
        </header>
        <h2 id="topics">Topics</h2>

<p>This post covers the twelth lecture in the course: “Text Retrieval.”</p>

<p>Retrieval – locating relevant information in a large knowledgebase - is also core to a variety of applications, relating closely to semantic similarity (previous lecture) and entity disambiguation (following lecture). Knowledge intensive NLP is also covered.</p>

<h2 id="lecture-video">Lecture Video</h2>

<p><em>Intro and Question Answering</em></p>

<p><a href="https://www.youtube.com/watch?v=iprWyzVoQQY&amp;ab_channel=MelissaDell" target="_blank">
 <img src="http://img.youtube.com/vi/iprWyzVoQQY/mqdefault.jpg" alt="Watch the video" width="560" height="315" />
</a></p>

<p><em>Retrieval and Open Domain Question Answering</em></p>

<p><a href="https://www.youtube.com/watch?v=-FbKAMaP0sM&amp;ab_channel=MelissaDell" target="_blank">
 <img src="http://img.youtube.com/vi/-FbKAMaP0sM/mqdefault.jpg" alt="Watch the video" width="560" height="315" />
</a></p>

<p><em>Retrieval Augmented Language Modeling</em></p>

<p><a href="https://www.youtube.com/watch?v=XC4eFiIMOmY&amp;ab_channel=MelissaDell" target="_blank">
 <img src="http://img.youtube.com/vi/XC4eFiIMOmY/mqdefault.jpg" alt="Watch the video" width="560" height="315" />
</a></p>

<p><a href="https://www.dropbox.com/s/d60x6oswis5xjnm/lecture_retrieval.pdf?dl=0">Lecture notes</a></p>

<h2 id="references-cited-in-lecture-12-text-retrieval">References Cited in Lecture 12: Text Retrieval</h2>

<h4 id="academic-papers">Academic Papers</h4>

<p>Karpukhin, Vladimir, Barlas Oğuz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. “<a href="https://arxiv.org/pdf/2004.04906">Dense passage retrieval for open-domain question answering</a>.” arXiv preprint arXiv:2004.04906 (2020).</p>

<p>Khattab, Omar, and Matei Zaharia. “<a href="https://dl.acm.org/doi/pdf/10.1145/3397271.3401075">Colbert: Efficient and effective passage search via contextualized late interaction over bert.</a>” In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, pp. 39-48. 2020.</p>

<p>Santhanam, Keshav, Omar Khattab, Jon Saad-Falcon, Christopher Potts, and Matei Zaharia. “<a href="https://arxiv.org/pdf/2112.01488">Colbertv2: Effective and efficient retrieval via lightweight late interaction.</a>” arXiv preprint arXiv:2112.01488 (2021).</p>

<p>Luan, Yi, Jacob Eisenstein, Kristina Toutanova, and Michael Collins. “<a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00369/100684">Sparse, dense, and attentional representations for text retrieval.</a>” Transactions of the Association for Computational Linguistics 9 (2021): 329-345.</p>

<p>Gao, Luyu, Xueguang Ma, Jimmy Lin, and Jamie Callan. “<a href="https://arxiv.org/pdf/2212.10496">Precise Zero-Shot Dense Retrieval without Relevance Labels.</a>” arXiv preprint arXiv:2212.10496 (2022).</p>

<p>Tam, Weng Lam, Xiao Liu, Kaixuan Ji, Lilong Xue, Xingjian Zhang, Yuxiao Dong, Jiahua Liu, Maodi Hu, and Jie Tang. “<a href="https://arxiv.org/pdf/2207.07087">Parameter-efficient prompt tuning makes generalized and calibrated neural text retrievers.</a>” arXiv preprint arXiv:2207.07087 (2022).</p>

<p><em>Self-supervised training</em></p>

<p>Ram, Ori, Gal Shachaf, Omer Levy, Jonathan Berant, and Amir Globerson. “<a href="https://arxiv.org/pdf/2112.07708">Learning to retrieve passages without supervision.</a>” arXiv preprint arXiv:2112.07708 (2021).</p>

<p>Sachan, Devendra Singh, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. “<a href="">Improving Passage Retrieval with Zero-Shot Question Generation.</a>” arXiv preprint arXiv:2204.07496 (2022).</p>

<p>Sachan, Devendra Singh, Mike Lewis, Dani Yogatama, Luke Zettlemoyer, Joelle Pineau, and Manzil Zaheer. “<a href="https://arxiv.org/pdf/2204.07496">Questions are all you need to train a dense passage retriever.</a>” arXiv preprint arXiv:2206.10658 (2022).</p>

<p><em>Knowledge Intensive NLP</em></p>

<p>Lewis, Patrick, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler et al. “<a href="https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf">Retrieval-augmented generation for knowledge-intensive nlp tasks.</a>” Advances in Neural Information Processing Systems 33 (2020): 9459-9474.</p>

<p>Borgeaud, Sebastian, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche et al. “<a href="https://proceedings.mlr.press/v162/borgeaud22a/borgeaud22a.pdf">Improving language models by retrieving from trillions of tokens.</a>” In International conference on machine learning, pp. 2206-2240. PMLR, 2022.</p>

<h4 id="other-resources">Other Resources</h4>

<p><a href="https://github.com/facebookresearch/DPR">DPR Codebase</a></p>

<p><a href="https://ai.facebook.com/blog/-advances-toward-ubiquitous-neural-information-retrieval">Advances towards ubiquitous neural information retrieval</a> (Meta AI blog post)</p>

<p><a href="http://mitchgordon.me/ml/2022/07/01/retro-is-blazing.html">RETRO Blog Post</a></p>

<p><em>Image Source</em>: Chan, D., Fisch, A., Weston, J., Bordes, A. (2017). Reading Wikipedia to Answer Open-Domain Questions.</p>

    </div>
  </div>
</article>

        </div>
    </div>
    

</body>

</html>