<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>EconDL | LinkTransformer</title>
    <meta name="description" content="A Unified Python Package for Record Linkage with Transformer Models">

    <meta property="og:title" content="LinkTransformer">
    <meta property="og:type" content="website">
    <meta property="og:url" content="/resources/linktransformer">
    <meta property="og:description" content="A Unified Python Package for Record Linkage with Transformer Models">
    <meta property="og:site_name" content="">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:url" content="/resources/linktransformer">
    <meta name="twitter:title" content="LinkTransformer">
    <meta name="twitter:description" content="A Unified Python Package for Record Linkage with Transformer Models">

    <!-- TODO: Adding page thumbnail for social meida -->

    <!-- Canonical URL -->
    <link rel="canonical" href="/resources/linktransformer">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/assets/css/bulma.css">
    <link rel="stylesheet" href="/assets/css/syntax/manni.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
          inlineMath: [ ['$','$'] ],
          displayMath: [ ['$$','$$'] ],
          processEscapes: true,
        }
      });
    </script>
    
    <script type="text/javascript"
            src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    
    <!-- Add link to h2 ... h6 -->
    <!-- Ref: https://ben.balter.com/2014/03/13/pages-anchor-links/ -->
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script>
      $(function() {
        return $("h2, h3, h4, h5, h6").each(function(i, el) {
          var $el, icon, id;
          $el = $(el);
          id = $el.attr('id');
          icon = '<i class="fas fa-link"></i>';
          if (id) {
            return $el.append($("<a />").addClass("header-link").attr("href", "#" + id).html(icon));
          }
        });
      });
    </script>
    
    <script src="/assets/js/bulma-collapsible.min.js"></script>

    <!-- Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '');
</script>


</head>

<body>

    <div class="section">            
        <div class="container">
            
                <nav class="navbar" role="navigation">
    <div class="navbar-brand">
        <a class="navbar-item site-title" href="/">
            <strong>EconDL</strong>
        </a>

        <div class="navbar-burger" data-target="navbar-main"
            onclick="document.querySelector('.navbar-menu').classList.toggle('is-active');">
            <span></span>
            <span></span>
            <span></span>
        </div>
    </div>

    <div class="navbar-menu" id="navbar-main">
        <div class="navbar-end">
            <!-- navbar items -->
            
                
                    <a href="/" class="navbar-item"></a>
                
            
                
                    <a href="/packages.html" class="navbar-item">Packages</a>
                
            
                
                    <a href="/datasets.html" class="navbar-item">Datasets</a>
                
            
            <div class="navbar-item">
                
            </div>
        </div>
    </div>
</nav>
<div class="is-divider" style="margin-top: 0.5rem; margin-bottom: 3rem;"></div>
  
            
            <article class="content" style="margin-top: 3rem">
  <div class="columns">
    <div class="column is-2 is-hidden-mobile">
    </div>
    <div class="column is-8">
        <header class="article-header">
            <h1>LinkTransformer</h1>
            <div class="article-list-footer">
    <span class="article-list-date">
        December 13, 2024
    </span>
    <span class="article-list-divider">-</span>
    <span class="article-list-minutes">
        
        
        2 minute read
        
    </span>
    </span>
    
    <span class="article-list-divider">-</span>
    <span class="article-list-cat">Category:</span>
    
    <span class="field">
        
        <a href="/category/software" class="article-list-item">
            Software
        </a>
        
        
    </span>
    
    <span class="field">
        
    </span>
</div>
        </header>
        <p><img src="/assets/projects/lt_logo.png" alt="" /></p>

<p>Introducing LinkTransformer: LinkTransformer brings the advantages of AI to standard data frame manipulation tasks like merges, deduplication, and clustering, making it easy to use large language models in a standard data wrangling workflow.</p>

<p><a href="https://linktransformer.github.io/">Webpage</a></p>

<p><a href="https://scholar.harvard.edu/sites/scholar.harvard.edu/files/dell/files/linkt.pdf">Paper</a></p>

<p><a href="https://github.com/dell-research-harvard/linktransformer">Github</a></p>

<p><a href="https://colab.research.google.com/drive/1SAvQdgYiX2CinoTC8Y5qtKScNwx3DYXf#scrollTo=jR0-0I6jPm2S">Intoductory Notebook</a></p>

<p><a href="https://colab.research.google.com/drive/1OqUB8sqpUvrnC8oa_1RoOUzV6DaAKL4N">Inference Deep-Dive</a></p>

<p><a href="[ttps://colab.research.google.com/drive/1tHitPGjMMI2Nvh4wwA8rdcbYfbLaJDvg](https://colab.research.google.com/drive/1tHitPGjMMI2Nvh4wwA8rdcbYfbLaJDvg)">Training Deep-Dive</a></p>

<p>Merge with transformer language models like you would in Pandas. The API is designed to be as simple as possible and very familiar to practitioners coming from other environments like R and Stata.</p>

<p><img src="/assets/projects/lt_image.png" alt="" /></p>

<p>LinkTransformer supports all models on the Hugging Face Hub and OpenAI Embedding models. We’ve also trained our own collection of over 20 open-source language models for different languages and tasks. A guide to selecting models is <a href="https://colab.research.google.com/drive/1SAvQdgYiX2CinoTC8Y5qtKScNwx3DYXf#scrollTo=jR0-0I6jPm2S">here</a></p>

<p>LinkTransformer supports a wide range of data wrangling tasks with transformers: standard merging, merge with blocking or multiple keys, cross-lingual merges (no need to translate), 1-m and m-m merges, aggregation/classification, clustering and de-duplication. <a href="https://colab.research.google.com/drive/1OqUB8sqpUvrnC8oa_1RoOUzV6DaAKL4N">Examples</a></p>

<p>Training your own models is as easy as one line of code, with most of the heavy lifting done behind the scenes.  You can fine-tune any pretrained model from Hugging Face. Learn more at our <a href="https://github.com/dell-research-harvard/linktransformer">repo</a> and <a href="[ttps://colab.research.google.com/drive/1tHitPGjMMI2Nvh4wwA8rdcbYfbLaJDvg](https://colab.research.google.com/drive/1tHitPGjMMI2Nvh4wwA8rdcbYfbLaJDvg)">demo notebook</a></p>

<p><img src="/assets/projects/train.png" alt="" /></p>

<p>LinkTransformer aims to create a community for deep record linkage, streamlining the distribution of record linkage models and promoting the reusability and reproducibility of pipelines.  Users can tag and share their models on the Hugging Face hub with a single line of code.</p>

<p><img src="/assets/projects/hub.png" alt="" /></p>

<p>This is our initial release, and we welcome feedback via Github. Planned features for the next release include integrating vision transformer models for visual record linkage (forgo OCR altogether!) and FAISS GPU support.</p>

<p>If you find LinkTransformer useful, please cite it and consider starring our repo  <a href="https://github.com/dell-research-harvard/linktransformer">repo</a>. We funded LT out of the PI’s very limited unrestricted funds, and to maintain/expand we need to show potential funders that it is having a positive impact on the community!</p>

    </div>
  </div>
</article>

        </div>
    </div>
    

</body>

</html>